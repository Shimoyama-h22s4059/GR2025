{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ESM の埋め込みベクトルを取得する",
   "id": "8de64cabac680bc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 必要なライブラリのインストール",
   "id": "fa0f64483ca4ba7f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T14:31:12.534121Z",
     "start_time": "2025-08-03T14:31:11.317919Z"
    }
   },
   "source": "!pip install fair-esm",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fair-esm in e:\\gr2025\\.venv\\lib\\site-packages (2.0.0)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:26:43.951634Z",
     "start_time": "2025-10-04T05:26:34.208933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import esm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO"
   ],
   "id": "5cbdc3dd44354a03",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:27:05.526828Z",
     "start_time": "2025-10-04T05:26:56.857426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 一応環境変数を変更\n",
    "os.environ[\"HF_HOME\"] = \"D:/hf-home\"\n",
    "\n",
    "# ESM-1b を読み込み\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# デバイスを決定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 評価モードにする\n",
    "model.eval()"
   ],
   "id": "61b4289cd634bc76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinBertModel(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (embed_positions): LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
       "  (emb_layer_norm_before): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:27:09.742426Z",
     "start_time": "2025-10-04T05:27:09.735062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"../data/gds_dataset\"  # データセットのディレクトリ\n",
    "filenames = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))]  # .txt のみ抽出\n",
    "\n",
    "save_to = \"../data/embedding-vectors/esm1b\"\n",
    "os.makedirs(save_to, exist_ok=True)  # 保存先ディレクトリの作成"
   ],
   "id": "c26fe7cac9e93f95",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:34:08.881431Z",
     "start_time": "2025-10-04T05:34:08.878879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exclusion_bases = list(\"BJOUXZ\")\n",
    "\n",
    "def check_valid_seq(seq):\n",
    "    \"\"\"\n",
    "    有効なアミノ酸配列かどうかを返す関数\n",
    "    :param seq: タンパク質配列\n",
    "    :return: 有効なタンパク質ならば True\n",
    "    \"\"\"\n",
    "\n",
    "    # 配列長が1000以上なら除外\n",
    "    if len(seq) >= 1000:\n",
    "        return False\n",
    "\n",
    "    # \"BJOUXZ\" が含まれていたら除外\n",
    "    for base in exclusion_bases:\n",
    "        if base in seq:\n",
    "            return False\n",
    "\n",
    "    return True"
   ],
   "id": "33c061f516f0f3fb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 データの作成",
   "id": "5ca7d823a6c85b89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:34:41.588857Z",
     "start_time": "2025-10-04T05:34:41.414506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as handle:\n",
    "        for record in SeqIO.parse(filename, \"fasta\"):\n",
    "            accession_number = record.id.split(\"|\")[3] if len(record.id.split(\"|\")[3]) > 0 else \"Unknown\"  # アクセッション番号を取得\n",
    "            seq = record.seq\n",
    "\n",
    "            # 有効なアミノ酸配列かを確認\n",
    "            if check_valid_seq(seq):\n",
    "                data.append((accession_number, seq))  # データに追加"
   ],
   "id": "8b4720d3b6a894e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 516.36it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. ESM-1b で埋め込みベクトルを作成 して npy へ保存",
   "id": "ca3f557e3a5941f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T05:58:48.379855Z",
     "start_time": "2025-10-04T05:39:35.432524Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3858/3858 [19:12<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "execution_count": 10,
   "source": [
    "batch_size = 2  # バッチサイズ\n",
    "\n",
    "number = 1\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    batch = data[i:i + batch_size]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    # 残基ごとの表現を抽出する\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "\n",
    "    reps = results[\"representations\"][33].to(\"cpu\")\n",
    "\n",
    "    for b in range(len(batch)):\n",
    "        rep = reps[b, 1:len(batch_strs[b]) + 1, :].numpy()\n",
    "        np.save(os.path.join(save_to, f\"{number}.npy\"), rep)\n",
    "        number += 1"
   ],
   "id": "65b2ac0c3240ee0f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
