# GR2025

## TL;DR
卒業研究用のリポジトリです

## 使用ライブラリ
以下の通りです

| 名前              |     バージョンなど |
|:----------------|------------:|
| Python          |      3.13.3 |
| PyTorch         | 2.7.1+cu118 |
| torchvision     | 2.7.1+cu118 |
| huggingface_hub |      0.33.4 |

## 使用したTransformerモデル
- [`google/vit-base-patch16-224-in21k`](https://huggingface.co/google/vit-base-patch16-224-in21k)
- [`openai/clip-vit-base-patch16`](https://huggingface.co/openai/clip-vit-base-patch16)

## 独自データセットの作成
- `generating-my-gpcr-dataset.md` を参照してください

## ハイパーパラメータ調整

### 学習率を調整
- 以下のパラメータは固定
    - バッチサイズ： $16$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | Weight Decay | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|-------------:|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-4 |            0 |       0.071040 |     0.437467 |     0.910703 |            0.604732 |         0.603199 |     0.587686 |
|         16 |     20 |          1E-4 |            0 |       0.008440 |     0.240316 |     0.964879 |            0.791859 |         0.764867 |     0.775062 |
|         16 |     20 |          5E-5 |            0 |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     20 |          1E-5 |            0 |       0.016240 |     0.169917 |     0.968377 |            0.791883 |         0.764964 |     0.776294 |
|         16 |     20 |          5E-6 |            0 |       0.032420 |     0.164040 |     0.965267 |            0.743238 |         0.694010 |     0.706675 |
|         16 |     20 |          1E-6 |            0 |       0.206520 |     0.252162 |     0.948677 |            0.559546 |         0.530088 |     0.542294 |


### バッチサイズを調整
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | Weight Decay | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|-------------:|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|          8 |     20 |          5E-5 |            0 |       0.008220 |     0.221959 |     0.968896 |            0.808218 |         0.803892 |     0.804725 |
|         16 |     20 |          5E-5 |            0 |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         32 |     20 |          5E-5 |            0 |       0.009960 |     0.175895 |     0.969025 |            0.798944 |         0.777382 |     0.784098 |


### エポック数を調整
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - バッチサイズ： $16$

| Batch Size | Epochs | Learning Rate | Weight Decay | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|-------------:|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-5 |            0 |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     30 |          5E-5 |            0 |       0.008260 |     0.217226 |     0.969802 |            0.800351 |         0.770753 |     0.781760 |
|         16 |     40 |          5E-5 |            0 |       0.007560 |     0.227702 |     0.969283 |            0.800521 |         0.792324 |     0.792730 |


### 重み減衰を調整
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - バッチサイズ： $16$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | Weight Decay | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|-------------:|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-5 |            0 |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     20 |          5E-5 |     1.00E-05 |       0.008660 |     0.188325 |     0.970839 |            0.821716 |         0.793379 |     0.805547 |
|         16 |     20 |          5E-5 |     1.00E-04 |       0.008740 |     0.197480 |     0.970062 |            0.820191 |         0.807598 |     0.813441 |
|         16 |     20 |          5E-5 |     1.00E-03 |       0.008700 |     0.196449 |     0.970580 |            0.819232 |         0.807477 |     0.812986 |


### ドロップアウト率を調整
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - バッチサイズ： $16$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | Dropout | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|--------:|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-5 |       0 |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     20 |          5E-5 |     0.1 |       0.008640 |     0.201080 |     0.968896 |            0.808844 |         0.806231 |     0.806657 |
|         16 |     20 |          5E-5 |     0.2 |       0.008620 |     0.203114 |     0.970062 |            0.820370 |         0.805162 |     0.812070 |


### モデルの変更
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - バッチサイズ： $16$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | model                               | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|:------------------------------------|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-5 | `google/vit-base-patch16-224-in21k` |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     20 |          5E-5 | `openai/clip-vit-base-patch16`      |       0.012860 |     0.696410 |     0.925739 |            0.755241 |         0.718175 |     0.731534 |


### 空のモデルとの比較
- 以下のパラメータは固定
    - 学習率： $5 \times 10^{-5}$
    - バッチサイズ： $16$
    - エポック数： $20$

| Batch Size | Epochs | Learning Rate | model       | Avg Train Loss | Avg Val Loss | Avg Accuracy | Avg Macro Precision | Avg Macro Recall | Avg Macro F1 |
|-----------:|-------:|--------------:|:------------|---------------:|-------------:|-------------:|--------------------:|-----------------:|-------------:|
|         16 |     20 |          5E-5 | Pre-trained |       0.008640 |     0.197400 |     0.970061 |            0.811944 |         0.793896 |     0.799329 |
|         16 |     20 |          5E-5 | Empty       |       0.013920 |     0.761775 |     0.916666 |            0.714810 |         0.694702 |     0.695624 |


## 更新履歴

### 2025/07/20
- 機械学習の基礎を学びました
- HuggingFaceの `datasets` を用いてMNISTデータセットを学習させました
- Google Colab でも動かしてみましたが、無料枠では限界を感じました
  - 研究するなら金払え！！！！
  - <img width="288" height="215" alt="{5880D043-7314-4998-8BEC-A9F857CCEFBB}" src="https://github.com/user-attachments/assets/e572d875-77d1-4b93-98cf-efae1a635d5a" />
- PyTorch を動かすのにPythonのバージョンをあれこれ揃えないといけない

### 2025/07/21
- 昨日、HuggingFaceおよびPyTorchを用いた学習方法を学んだので、少し動かしてみた
- MNISTの学習に4時間程度要しました
  - epoch: 3
  - batch size: 64
- 手書き文字認識する簡単なWebアプリを実装
- Flask で作成、`app.py` にて実行可能

### 2025/10/29
- 一旦ハイパーパラメータの調整をする方針で進める
- 埋め込みベクトルを取得して画像生成する手法もやる

### 2025/11/18
- [BIAS-PROFS](https://www.cs.kent.ac.uk/projects/biasprofs/) データセットに色々問題が合った
- 重複している配列を1つにまとめる
  - 複数クラスにまたがっている場合は削除
- [InterPro](https://www.ebi.ac.uk/interpro/) データセットも使うようにする
